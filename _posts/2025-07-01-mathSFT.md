---
layout: post
title: "大模型数学推理能力的SFT训练"
date: 2022-06-06
categories: zsh blogging
---

经过一些RL之后，我怀疑先要进行比较好的SFT，作为RL的初始解，但SFT的数据量和质量是好的，我对比了一下我自己SFT和R1-distill，从数学模型上效果差距较大。如果弥补了这种差距，继续RL才比较靠谱，所以先要排查一下自己SFT为啥不好。

## 1. 现有数据集排查

### 1.1 数据集概览表

| 出品方 | 数据集名称 | 数据量 | 是否采用 | 质量评级 | 主要特点 |
|--------|-----------|--------|----------|----------|----------|
| DeepSeek | DeepSeek-R1-Distill-data-110k | 11万 | ✅ | ⭐⭐⭐⭐⭐ | 保留数据来源，介绍打分方式，难题解对，甚至能纠正题目 |
| ShareGPT | ShareGPT | - | 🔄 TODO | - | Paper: https://arxiv.org/pdf/2504.16891 |
| PrimeIntellect | INTELLECT-MATH-SFT-Data | 70万（过滤后） | ✅ | ⭐⭐⭐⭐ | 量大管饱，质量较高、难度中等，system prompt完善 |
| Numina | NuminaMath-QwQ-CoT | 500万 | ⚠️ | ⭐⭐⭐ | 量大，但质量存在问题，训练效果不如预期 |
| - | qwq_synthetic_sft_data_math | - | ❌ | ⭐ | 质量非常差，问题和答案错配 |
| - | MathInstruct | - | ✅ | ⭐⭐⭐⭐ | 质量较高，需要格式转换，含PoT示例 |
| - | sft-data-math | - | ⚠️ | ⭐⭐ | 无readme，题目和答案存在多处瑕疵 |
| O1-OPEN | OpenO1-SFT-MATH | - | ⚠️ | ⭐⭐ | 需要去重和过滤，训练后分数下降 |
| Alpaca | alpaca-sft-math-tasks | - | ✅ 部分 | ⭐⭐⭐ | 类型题，启发编程工具需求 |
| Alpaca | alpaca-sft-math-factorial | - | ❌ | - | n! % M 计算题 |
| Alpaca | alpaca-sft-math-hard2 | - | 🔄 审批中 | - | - |
| - | tulu-3-sft-math | - | ✅ | ⭐⭐⭐ | 偏简单，基本正确，无think模式 |
| Belle | Belle_school_math | - | ❌ | ⭐⭐ | 偏简单，题型重复，质量不高 |
| Kyara | kyara-chinese-math | - | ❌ | ⭐⭐ | 偏简单，题型重复 |

### 1.2 重点数据集详细分析

#### 1.2.1 DeepSeek-R1-Distill-data-110k ⭐⭐⭐⭐⭐

**基本信息**：
- 数据量：11万条
- 采用状态：✅ 推荐使用

**优点**：
1. 保留了数据来源，可追溯性强
2. 介绍了打分方式：
   - 使用Math-verify解析问题
   - 表达式消歧处理
   - 多线程安全机制
   - 使用模型进行评分

**Case Study**：
- 难题解答正确率高
- 甚至能够纠正题目中的错误

---

#### 1.2.2 INTELLECT-MATH-SFT-Data ⭐⭐⭐⭐

**基本信息**：
- 数据量：过滤后约70万条可用
- 采用状态：✅ 推荐使用
- 评价：量大管饱

**特点**：
- 无遵循推理输出格式（需要转换）
- 质量较高、难度中等
- System prompt更加完善

**System Prompt示例**：
```json
{
  "content": "Solve the following math problem efficiently and clearly. Think carefully and step by step about your response and reason before providing a final response. Conclude your response with: \n\nTherefore, the final answer is: $\\boxed{answer}$. I hope it is correct.\n\nWhere [answer] is just the final number or expression that solves the problem. If the question is a multiple choice question, [answer] should be the letter indicating your correct response (e.g. \\text{A} or \\text{B}).",
  "role": "system"
}
```

**数据验证逻辑**：
```python
instruction = item["messages"][1]["content"]
output = item["messages"][2]["content"]
final_result = output.rsplit("\\boxed{", 1)[-1].rsplit("}", 1)[0]
if len(final_result) > 5 * len(item["ground_truth"]):  # 一些数据在犹豫二选一
    continue
final_result = "".join(final_result.replace("\\dfrac", "\\frac").split())
gt = "".join(item["ground_truth"].replace("\\dfrac", "\\frac").split())

sig1 = 1
if final_result != gt and gt not in final_result and final_result not in gt:
    sig1 = 0
sig2 = 0
try:
    if verify(parse(f"${final_result}$"), parse(f"${gt}$")):
        sig2 = 1
except:
    pass
if sig1 == 0 and sig2 == 0:
    continue
```

**Ground Truth说明**：
- GT来源未明确说明，怀疑是从回答中抽取的
- 可用来检查回答是否异常，从而进行过滤

---

#### 1.2.3 NuminaMath-QwQ-CoT ⭐⭐⭐

**基本信息**：
- 数据量：500万条
- 采用状态：⚠️ 谨慎使用
- 评价：量大但质量存在问题

**问题分析**：
- 无遵循推理输出格式
- 训练效果不理想：
  - 500万条训练7B模型（intellect-math应该也是基于qwen训练的）
  - 只达到deepseek-R1-distill-Qwen1.5B的水平
  - 对比AIME2024、MATH-500数据，效果不如Qwen3 1.7B
  - 距离deepseek-R1-distill-Qwen7B相差较大
  - 说明数据质量存在一定问题

**Case Study发现的问题**：

| 问题类型 | Problem ID | 具体描述 | 严重程度 |
|----------|-----------|----------|----------|
| 数据泄露 | 650008 | 答案结束后出现"human assistant"字样 | 🔴 高 |
| 超长截断 | 650002 | 证明题超长被截断（题目太难） | 🟡 中 |
| 正确证明 | 650560 | 证明看起来是对的 | 🟢 无问题 |
| 缺少条件 | 650576 | 疑似缺少图片，提到"The figure" | 🔴 高 |
| 难度大 | - | 部分题目难以理解 | 🟡 中 |
| 假错误(GT错) | - | GT错误，解答中的96是正确的 | 🟡 中 |
| 假错误(都对) | 650569 | GT和解答都正确但被标记为错 | 🟡 中 |
| 真错误 | - | 确实存在错误 | 🔴 高 |

**证明题情况**：
- 较多证明题（prompt含有"Prove that"字样）
- 部分证明正确，部分被截断

---

#### 1.2.4 qwq_synthetic_sft_data_math ⭐ （不采用）

**问题**：
- ❌ 没有readme
- ❌ 质量非常差
- ❌ 几乎所有的问题和答案都是错配的

**结论**：不建议使用

---

#### 1.2.5 MathInstruct ⭐⭐⭐⭐

**基本信息**：
- 参考论文：https://arxiv.org/pdf/2309.05653v3
- 采用状态：✅ 推荐使用

**重要启发**：
- Paper的附录中有例子证明：**PoT（Program of Thought）对比CoT是很好的补充**
- 受此启发，数学解题能力建设中也需要编程的tool调用

**特点**：
- ✅ 质量较高，答案和过程一般都没有问题
- ⚠️ 不是推理格式，需要转换和校验

**Case Study**：
- 存在部分格式不对的情况

---

#### 1.2.6 sft-data-math ⭐⭐

**基本问题**：
- ❌ 无readme
- ⚠️ 题目和答案存在多处瑕疵

**Case Study发现的问题**：

| 问题类型 | 具体描述 | 备注 | 严重程度 |
|----------|----------|------|----------|
| 选项缺失 | 题目选项中没有正确答案（-1+5i），解答也不对 | - | 🔴 高 |
| 题目不严谨 | 题目没有唯一解 | remark：50x=60(x-y) x,y是整数 | 🟡 中 |
| 答案瑕疵 | 区间的开闭和规范写法问题 | 正确答案应为$(1/4,1/2]$ | 🟡 中 |

---

#### 1.2.7 OpenO1-SFT-MATH ⭐⭐

**基本信息**：
- 采用状态：⚠️ 需要大量处理后使用

**存在的问题**：

| 问题类型 | 具体描述 | 处理方法 |
|----------|----------|----------|
| 训练效果差 | Readme显示训练后分数下降 | - |
| 数据重复 | Query重复 | 需要去重 |
| 不遵循指令 | 含有"write a program in Python"的题目，最终却是直接数学计算求解 | 全部删除 |
| 格式错误 | `<Thought>`,`</Thought>`,`<Output>`,`</Output>`数量不严格等于1 | 删除不符合的数据 |
| 数据错误 | 存在错误 | 参考：https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT/discussions/15 |

**处理建议**：
1. 对Query进行去重
2. 删除不遵循指令的数据
3. 删除格式不符合的数据
4. 进行正确性过滤

---

#### 1.2.8 Alpaca系列

**共同特点**：
- 都是类型题
- **启发**：对于固定算法的计算，需要编程工具

##### alpaca-sft-math-tasks ⭐⭐⭐（采样0.01，部分采用）

**包含的题型**：
- 求解GCD（辗转相除法）
- 证明素数
- 任何一对素数中找出和为N的最小素数（哥德巴赫猜想）

##### alpaca-sft-math-factorial （不采用）

**题型**：n! % M 计算题

##### alpaca-sft-math-hard2 （审批中）

**状态**：待审批

---

#### 1.2.9 简单数据集

##### tulu-3-sft-math ⭐⭐⭐

**基本信息**：
- 采用状态：✅ 用于训练无think模式

**特点**：
- 偏简单
- 基本正确
- 无think（也确实不需要）

**用途**：加入用于训练无think模式

---

##### Belle_school_math ⭐⭐ （不采用）

**特点**：
- 偏简单
- 基本正确
- 无think（也确实不需要）

**问题**：
- ❌ 都是简单的加减乘除应用题
- ❌ 题型和tulu3有重复
- ❌ 题目可能是生成的，质量不高

**结论**：不建议使用

---

##### kyara-chinese-math ⭐⭐ （不采用）

**特点**：
- 偏简单
- 基本正确
- 无think（也确实不需要）

**问题**：
- ❌ 都是简单的加减乘除应用题
- ❌ 题型和tulu3有重复

**结论**：不建议使用

---

### 1.3 数据集统计对比表

| 数据集 | 数据量 | 格式 | 难度 | 质量 | 是否需要转换 | 推荐度 |
|--------|--------|------|------|------|-------------|--------|
| DeepSeek-R1-Distill | 11万 | CoT | 高 | 极高 | 否 | ⭐⭐⭐⭐⭐ |
| INTELLECT-MATH-SFT | 70万 | CoT | 中 | 高 | 是 | ⭐⭐⭐⭐ |
| NuminaMath-QwQ-CoT | 500万 | CoT | 高 | 中 | 是 | ⭐⭐⭐ |
| MathInstruct | - | 混合 | 中 | 高 | 是 | ⭐⭐⭐⭐ |
| OpenO1-SFT-MATH | - | Thought | 中 | 中 | 是 | ⭐⭐ |
| alpaca-sft-math-tasks | - | 直接 | 低 | 中 | 是 | ⭐⭐⭐ |
| tulu-3-sft-math | - | 直接 | 低 | 高 | 否 | ⭐⭐⭐ |
| sft-data-math | - | CoT | 中 | 低 | 是 | ⭐⭐ |
| qwq_synthetic | - | - | - | 极低 | - | ❌ |
| Belle_school_math | - | 直接 | 低 | 低 | 否 | ❌ |
| kyara-chinese-math | - | 直接 | 低 | 低 | 否 | ❌ |

---

### 1.4 数据转换和校验方法

使用qwen3-14B进行检查的关键函数：

#### 1.4.1 正确性检查

```python
def output_correctness(instruction, output):
    prompt = f"""判断下面的回答是否正确，如果正确，返回1；如果错误，返回0。\n
        问题：{instruction}
        回答：{output}\n
        注意：
        - 直接返回1或0，不要添加任何其他内容。
        - 对于计算题，不仅要检查最终结果，还要检查计算过程是否正确。
        - 对于选择题，最终答案应该给出完整的选项和内容，不能只给出内容。
        - 对于证明题，证明过程要完整、严谨，不能有逻辑漏洞。"""
    
    response = vllm_chat(prompt, max_tokens=20)
    response = response.strip()
    return response.startswith("1")
```

#### 1.4.2 推理格式转换

```python
def reasoning_output_transform(instruction, output):
    prompt = f"""从题目和解答中，提取出解答的思考过程和最终结果，思考过程用<thought>...</thought>括起来，回答过程用<answer>...</answer>括起来。最终结果用\\boxed{{}}括起来。
        注意：是提取出给你的解答的思考过程和最终结果。不要自己解题！不要自己解题！
        1. 思考和回答都要使用和原始输入相同的语种，如果题目用中文，回答也要用中文，如果题目用英文，回答也要用英文
        2. 回答过程是思考过程的整理，不能是思考过程的简单复述
        3. 对于编写代码的题目，忠实提取代码内容，不要取代代码直接计算
        4. 如果题目是选择题，最终答案应该给出完整的选项和内容，不能只给出内容
        5. 不要脱离原来的解答自由发挥
        6. 你的输出始终以<thought>开头，以</answer>结尾
        ------
        示例输入1：
        题目：The distance between two stars is 6.52 x 10^5 light years. What is the distance between the two stars in parsecs? (1 parsec = 3.26 light years)\nAnswer Choices: (A) 2 x 10^5 (B) 4 x 10^6 (C) 5 x 10^7 (D) 7 x 10^7 (E) 9 x 10^8
        解答：Let's think about the multi-choice question. 6.52 x 10^5 ly / (3.26 ly/parsec) = 2 x 10^5 persec\\nThe answer is A.
        示例输出1：<thought>Let's think about the multi-choice question. 6.52 x 10^5 ly / (3.26 ly/parsec) = 2 x 10^5 persec</thought><answer>The answer is \\boxed{{A}}</answer>
        ------
        示例输入2：
        题目：等差数列的首项是3，公差是2，求前100项的和。
        解答：本题可先根据等差数列的性质表示出$a_n$，再根据求和公式$S_n=\\frac{{n}}{{2}}(a_1+a_n)$求出前100项和$S_{{100}}$。\\n- $a_n=1+2n$，$S_n=\\frac{{n}}{{2}}(a_1+a_n)=\\frac{{n}}{{2}}(3+1+2n)=n^2+2n$\\n- $S_{100}=100^2+2*100=10200$。
        示例输出2：<thought>本题可先根据等差数列的性质表示出$a_n$，再根据求和公式$S_n=\\frac{{n}}{{2}}(a_1+a_n)$求出前100项和$S_{{100}}$。\\n- $a_n=1+2n$，$S_n=\\frac{{n}}{{2}}(a_1+a_n)=\\frac{{n}}{{2}}(3+1+2n)=n^2+2n$\\n- $S_{100}=100^2+2*100=10200$</thought><answer>结果\\boxed{{10200}}</answer>\n
        题目：{instruction}
        解答：{output}"""

    response = vllm_chat(prompt, max_tokens=len(output) * 2)
    return response
```

#### 1.4.3 格式验证

```python
def reasoning_output_format_validate(content):
    if content.startswith("<thought>") and content.endswith("</answer>") \
        and content.count("<thought>") == 1 and content.count("</thought>") == 1 \
        and content.count("<answer>") == 1 and content.count("</answer>") == 1 \
        and content.count("\\boxed{") == 1:
        return True
    else:
        return False
```

#### 1.4.4 内容一致性验证

```python
def reasoning_output_content_validate(instruction, content1, content2):
    prompt = f"""比较下面对于同一个问题的两个回答，判断它们语义是否一致。
        如果回答的中间过程出现语义不一致，返回0；
        如果最终结果不完全一致（包括格式和语义，例如对于选择题，一个回答给出选项代码，一个回答给出选项内容，应该认为是不一致的），则返回0；
        
        问题：{instruction}
        ---
        回答1：{content1}
        ---
        回答2：{content2}
        ---
        注意：直接返回1或0，不要添加任何其他内容。"""
    
    response = vllm_chat(prompt, max_tokens=20)
    response = response.strip()
    return response.startswith("1")
```


## 2. 数据集小结

个人观点
- 三方API不能完全解决（1）题目有瑕疵（2）编程辅助计算（3）巧妙解法
- 公开数据集中的高质量数据也已经不少了，足够进行训练，其他的可以进行过滤（暂未考虑去重）
- 总体来看，数据出品方的口碑、处理过程的公开程度、生产数据所使用的模型智商，决定了数据的质量
- 但是公开数据集还缺少（1）证明题（2）题目有瑕疵（3）多小问（4）编程辅助计算（5）批改（6）巧妙解法 这几个类型
- 构造数学解题能力的时候需要考虑加入PoT（编程辅助计算）的数据


## 3. SFT对比

### 3.1 实验设置

- **目的**：佐证我们的SFT训练能力本身不弱于外部，从而证明我们能充分发挥自有数据的优势
- **数据**：math数据集问题，目前剩下306297条thinking格式的训练集
  - 从qwen1.5B（倒数第三列看）
    - 数据中可能还剩下一些没有完整的，自我重复过高的
    - 也可能1.5B过拟合了

### 3.2 模型对比表格

| 模型 | 说明 | 模型路径 |
|------|------|----------|
| Qwen3-0.6B | 基线模型 | - |
| Qwen3-1.7B | 基线模型 | - |
| Qwen2.5-0.5B-instruct | 基线instruct模型 | - |
| Qwen2.5-0.5B-instruct + SFT（数据无充分治理） | 在0.5B上进行SFT | - |
| Qwen2.5-1.5B-instruct | 基线instruct模型 | - |
| Qwen2.5-1.5B-instruct + SFT（数据无充分治理） | 在1.5B上进行SFT | - |
| Qwen2.5-1.5B-instruct + SFT（数据经过充分治理） | 在1.5B上进行SFT，数据经过治理 | `/data_share/zhangsiheng/data/sft/Qwen2.5-1.5B_exp2.2` |
| Qwen2.5-7B-instruct + SFT（数据经过充分治理） | 在7B上进行SFT，数据经过治理 | `/data_share/zhangsiheng/data/sft/Qwen2.5-7B_exp2.2` |
| DeepSeek-R1-Distill-Qwen-1.5B | 对比基准模型 | - |

### 3.3 测试案例对比

#### 案例1：1+1=?

| 模型 | 输出结果 | 耗时 | 评价 |
|------|----------|------|------|
| **Qwen2.5-1.5B-instruct + SFT（数据经过充分治理）** | 正确输出2，有完整的think过程和验证 | - | 思维过程完整，考虑多种方法验证 |
| **Qwen2.5-7B-instruct + SFT（数据经过充分治理）** | 正确输出2，有详细的think和answer分离 | 115.87s | 思维过程详细，格式规范 |
| **DeepSeek-R1-Distill-Qwen-1.5B** | 正确输出2，包含多个验证方法 | - | 考虑了多种解题方法，验证充分 |

#### 案例2：等差数列求和问题

**题目**：已知等差数列$\{a_n\}$的公差为$d=\frac{1}{2}$，且$a_2+a_4+a_6+...+a_{100}=80$，求该数列的前100项之和

| 模型 | 输出结果 | 耗时 | 评价 |
|------|----------|------|------|
| **Qwen2.5-1.5B-instruct + SFT（数据经过充分治理）** | 正确答案135，推导过程完整 | - | 使用多种方法验证，逻辑清晰 |
| **Qwen2.5-7B-instruct + SFT（数据经过充分治理）** | 正确答案135，详细的代数推导 | - | 步骤详细，包含完整的验证过程 |
| **某些模型** | 错误答案80，推导过程有误 | 43.40s | 计算错误，未正确理解题意 |

#### 案例3：不等式最小值问题

**题目**：若$a>0,b>0$且$a+b=2$，则$\frac{1}{a}+\frac{1}{b}$的最小值为多少？

| 模型 | 输出结果 | 耗时 | 评价 |
|------|----------|------|------|
| **Qwen2.5-1.5B-instruct + SFT（数据经过充分治理）** | 正确答案2，使用导数和柯西不等式验证 | - | 多方法验证，思路清晰 |
| **Qwen2.5-7B-instruct + SFT（数据经过充分治理）** | 正确答案2，详细的代数推导 | - | 步骤完整，验证充分 |

#### 案例4：物理问题（光速叠加）

**题目**：我打开手电筒，沿着光照射的方向向前跑，光照出的速度不就是光速叠加上我移动的速度，从而超过了光速吗？

| 模型 | 输出结果 | 评价 |
|------|----------|------|
| **Qwen2.5-1.5B-instruct + SFT（数据经过充分治理）** | 正确解释光速不变原理 | 理解相对论基本概念 |
| **Qwen2.5-7B-instruct + SFT（数据经过充分治理）** | 详细解释光速不变原理和相对论效应 | 概念准确，解释详细 |
| **某些模型** | 输出混乱或错误理解 | 未能正确理解光速不变原理 |

#### 案例5：函数极值问题

**题目**：求函数$f(x)=(1+2x) \ln (1+x)-x$的极值

| 模型 | 输出结果 | 耗时 | 评价 |
|------|----------|------|------|
| **Qwen2.5-1.5B-instruct + SFT（数据经过充分治理）** | 正确求得极小值为0（在x=0处） | - | 推导过程完整，包含一阶、二阶导数 |
| **Qwen2.5-7B-instruct + SFT（数据经过充分治理）** | 正确求得极小值为0 | 96.64s | 详细的导数计算和验证 |
| **某些模型** | 重复输出或计算错误 | - | 陷入循环，未能正确求解 |

### 3.4 总结

**关键发现**：
1. 即使到了Qwen3的8B、14B、32B，复杂数学问题也主要是"硬算"出来的
2. 经过充分数据治理的SFT模型在数学推理上表现显著提升
3. thinking格式的训练数据对提升推理能力有明显帮助
4. 模型大小对解题能力有影响，但数据质量同样重要


## 4. 后续工作
证明题数据集
TODO：如何设计system prompt
TODO：数据集来源开源
TODO：检查大模型判断过程正确与否的裁判精准率
题目有瑕疵，答案拒答或者修正题目
TODO：如何收集这类数据？
多个问题/小问逐一回答的数据集
TODO：通过过滤和构造，可以搜集这类数据
用编程来解决会更加好的数学题（通常以计算为主）
TODO：执行代码并获得结果，参考 https://zhuanlan.zhihu.com/p/673854403 进行实现
- 求均值、方差等统计量
- 求解GCD。比如求1177和99的最大公约数
- 求解余数。比如求101! Mod 23
- 求根。比如牛顿迭代法
- 复杂方程组求解。
批改数据集
TODO
- 判断对错（现有大模型具备了这个能力了）
- 错误步骤定位
- 错因分析
算力太强、反而不注重巧妙解法的数据集
由于引入编程，模型算力进一步加强，很多时候模型倾向于暴力求解，而非使用人类的解法
TODO：如何定义、收集这类数据？
- 变量代换【kimi，doubao都算错了】
  - case1：已知非0实数$$x,y$$满足$$x/y+y/x+2xy=x^2-y^2$$，求$$x^2+y^2$$的最小值
  - case2：已知$$x,y,z>0,x^2+y^2+z^2=1$$，求 $$\min \frac{(z+1)^2}{2xyz}$$和$$x+y+z-xyz$$的范围
- 几何求解
  - 已知 $$x^2+y^2=x^2+z^2+\sqrt{3}xz=y^2+z^2+yz = 16$$，求$$2xy+xz+\sqrt{3}yz$$

自研模型的校验调研
- math-verifier
- Alibaba + deepseek: https://arxiv.org/pdf/2406.14024v1