---
layout: post
title: "大模型数学推理能力的SFT训练"
date: 2025-07-01
categories: zsh blogging
---

经过一些RL之后，我怀疑先要进行比较好的SFT，作为RL的初始解，但SFT的数据量和质量是好的，我对比了一下我自己SFT和R1-distill，从数学模型上效果差距较大。如果弥补了这种差距，继续RL才比较靠谱，所以先要排查一下自己SFT为啥不好。

先说结论，通过对HF上公开的数学数据        <tr>
      <td>case3</td>
      <td>&lt;think&gt;<br>好吧，我现在要解这个等差数列的问题。题目说等差数列{a_n}的公差d=1/2，而且a2 + a4 + a6 + ... + a100 = 80。我需要找到这个数列的前100项之和。<br><br>首先，我应该回忆一下等差数列的一些基本公式。等差数列的第n项可以表示为a_n = a1 + (n-1)d，其中a1是首项，d是公差。这里d=1/2，所以我可以写出a_n = a1 + (n-1)(1/2)。<br><br>接下来，题目给出的是a2 + a4 + a6 + ... + a100 = 80。这些项都是偶数项，也就是说，它们的下标是偶数。我要计算的是从a2到a100，每隔一项取一个的和，也就是第2项到第100项，每隔一项取一个。<br><br>首先，我需要确定有多少项。从2到100，每隔一项，一共有多少项？可以用等差数列来计算项数。项数n可以用公式n = ((100 - 2)/2) + 1 = (98/2) + 1 = 49 + 1 = 50项。所以总共有50项。<br><br>现在，我需要求这50项的和。因为这是一个等差数列的和，我可以使用等差数列求和公式：S = n/2 * (a1 + a_n)，其中n是项数，a1是首项，a_n是第n项。<br><br>不过，这里的问题是，我不太确定首项a1是多少。所以我需要找到a1的值。因为我知道d=1/2，所以a2 = a1 + d = a1 + 1/2，a4 = a1 + 3d = a1 + 3/2，依此类推。所以a2, a4, a6, ..., a100构成一个新的等差数列，公差为2d=1。<br><br>接下来，我需要计算a2 + a4 + a6 + ... + a100的和，这实际上是从新数列a2, a4, a6, ..., a100的前50项和。这个新的数列的首项是a2 = a1 + 1/2，公差是1，项数是50。<br><br>现在，我可以使用等差数列求和公式来计算这个和：S = n/2 * [2a1 + (n-1)d]，这里n=50，a1=a2 = a1 + 1/2，d=1。<br><br>代入公式：<br>S = 50/2 * [2(a1 + 1/2) + (50-1)*1]<br>= 25 * [2a1 + 1 + 49]<br>= 25 * (2a1 + 50)<br><br>根据题目，这个和等于80，所以：<br>25*(2a1 + 50) = 80<br>两边同时除以25：<br>2a1 + 50 = 3.2<br>然后：<br>2a1 = -46.8<br>a1 = -23.4<br><br>现在，我已经知道了a1=-23.4，d=1/2。接下来，我需要计算前100项的和，也就是整个等差数列的前100项和。<br><br>使用等差数列求和公式：<br>S = n/2 * [2a1 + (n-1)d]<br>这里n=100，a1=-23.4，d=1/2。<br><br>代入：<br>S = 100/2 * [2*(-23.4) + (100-1)*(1/2)]<br>= 50 * [-46.8 + 49.5]<br>= 50 * 2.7<br>= 135<br><br>所以，前100项的和是135。<br>&lt;/think&gt;<br><br>该等差数列的前100项之和为135。<br><br>&lt;answer&gt;\boxed{135}\&lt;/answer&gt;</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>，个人认为，自己的SFT训练能力是对齐外部模型的报告的，一个最直接的证据就是：**在1.5B尺寸模型上能够增长出同样水平的数学解题能力**。下面分两部分，一部分是数据集，一部分是训练后的case分析。附表有更详细的数据集分析。


## 1. 现有数据集

总体来看，数据出品方的口碑、处理过程的公开程度、生产数据所使用的模型智商，决定了数据的质量。使用质量高的进行训练结果也会相对好一些。另外，公开数据集中的高质量数据也已经不少了（过滤后剩下306297条thinking格式数据 VS DS-distill-Qwen 80w，优势在我【大雾】），足够进行训练（暂未考虑去重）

- 调用三方API来生产数据不能解决以下问题: 
  - （1）题目有瑕疵: 此时期望response应该能对题目进行澄清、补全/修正条件之后进行求解，言之有理即可；
  - （2）编程辅助计算: 对于有固定算法的数学问题，期望response能编写代码来辅助计算，而非直接给出答案；
      *但是如果在APP上使用，又可以调起工具来解决:  https://www.doubao.com/thread/wcdfc4570c4b860ab）*
  - （3）巧妙解法: 对于一些需要巧妙解法的数学问题，期望能给出人类常用的巧妙解法，而非暴力求解（https://yb.tencent.com/s/mO3RahaJnaA2）；
      *模型太强，暴力求解太快了，起码不适合用于教学目的，大模型难道也有“知识的诅咒”？*
      ```
      ## TODO: 如何定义、收集这类数据？
      - 变量代换【kimi，doubao都算错了】
        - case1: 已知非0实数$$x,y$$满足$$x/y+y/x+2xy=x^2-y^2$$，求$$x^2+y^2$$的最小值
        - case2: 已知$$x,y,z>0,x^2+y^2+z^2=1$$，求 $$\min \frac{(z+1)^2}{2xyz}$$和$$x+y+z-xyz$$的范围
      - 几何求解
        - 已知 $$x^2+y^2=x^2+z^2+\sqrt{3}xz=y^2+z^2+yz = 16$$，求$$2xy+xz+\sqrt{3}yz$$
    ```
  - （4）适应不同学段: 根据不同学段的论域来解决问题，比如在虚数域解方程的时候会比实数域有更多解，三方API通常会默认一个论域来进行。
- 公开数据集缺少以下类型的高质量SFT数据，我尝试对某几类给出以下构造方案（可惜我对于形式化数学知之甚少，是否可以用形式化数学的方法从解题步骤反向构造题目，希望有大佬给指点一下）: 
  - （1）证明题: HOW？
  - （2）题目有瑕疵: 分为条件不全、条件矛盾；对于条件不全的，是否可以让模型来改写正常问题使之缺少条件，然后让模型对照原题进行回答（补全条件+解答），构成SFT数据。对于条件矛盾的，暂时没有好的构造思路。
  - （3）多小问: 分为多个问题逐一回答然后统合起来，构成SFT数据。
  - （4）编程辅助计算: 搜集一堆code snippets，随机生成入参，运行代码，得到结果，然后让模型对入参生成题目，统合code和结果（参考https://zhuanlan.zhihu.com/p/673854403）生成SFT数据。
  - （5）巧妙解法: http://xhslink.com/o/7YYeHGBqzAZ 参考这类，是否能把构造法给到大模型作为prompt生成题目和解答，构成SFT数据。



### 1.1 数据集概览表

| 出品方 | 数据集名称 | 数据量 | 有无think | 是否需要转换 | 是否采用 | 推荐度 | 主要特点 |
|--------|-----------|--------|----------|-------------|----------|--------|----------|
| DeepSeek | DeepSeek-R1-Distill-data-110k | 11万 | ✅ CoT | 否 | ✅ | ⭐⭐⭐⭐⭐ | 保留数据来源，介绍打分方式，难题解对，甚至能纠正题目 |
| ShareGPT | ShareGPT | - | - | - | 🔄 TODO | - | Paper: https://arxiv.org/pdf/2504.16891 |
| PrimeIntellect | INTELLECT-MATH-SFT-Data | 70万（过滤后） | ✅ CoT | 是 | ✅ | ⭐⭐⭐⭐ | 量大管饱，质量较高、难度中等，system prompt完善 |
| Numina | NuminaMath-QwQ-CoT | 500万 | ✅ CoT | 是 | ⚠️ | ⭐⭐⭐ | 量大，但质量存在问题，训练效果不如预期 |
| - | qwq_synthetic_sft_data_math | - | - | - | ❌ | ❌ | 质量非常差，问题和答案错配 |
| - | MathInstruct | - | ✅ 混合 | 是 | ✅ | ⭐⭐⭐⭐ | 质量较高，需要格式转换，含PoT示例 |
| - | sft-data-math | - | ✅ CoT | 是 | ⚠️ | ⭐⭐ | 无readme，题目和答案存在多处瑕疵 |
| O1-OPEN | OpenO1-SFT-MATH | - | ✅ Thought | 是 | ⚠️ | ⭐⭐ | 需要去重和过滤，训练后分数下降 |
| Alpaca | alpaca-sft-math-tasks | - | ❌ 直接 | 是 | ✅ 部分 | ⭐⭐⭐ | 类型题，启发编程工具需求 |
| Alpaca | alpaca-sft-math-factorial | - | ❌ 直接 | - | ❌ | ❌ | n! % M 计算题 |
| Alpaca | alpaca-sft-math-hard2 | - | - | - | 🔄 审批中 | - | - |
| - | tulu-3-sft-math | - | ❌ 直接 | 否 | ✅ | ⭐⭐⭐ | 偏简单，基本正确，无think模式 |
| Belle | Belle_school_math | - | ❌ 直接 | 否 | ❌ | ❌ | 偏简单，题型重复，质量不高 |
| Kyara | kyara-chinese-math | - | ❌ 直接 | 否 | ❌ | ❌ | 偏简单，题型重复 |

### 1.2 用Qwen3-14B进行数据检查和转换

- 正确性检查

```python
def output_correctness(instruction, output):
    prompt = f"""判断下面的回答是否正确，如果正确，返回1；如果错误，返回0。\n
        问题: {instruction}
        回答: {output}\n
        注意: 
        - 直接返回1或0，不要添加任何其他内容。
        - 对于计算题，不仅要检查最终结果，还要检查计算过程是否正确。
        - 对于选择题，最终答案应该给出完整的选项和内容，不能只给出内容。
        - 对于证明题，证明过程要完整、严谨，不能有逻辑漏洞。"""
    
    response = vllm_chat(prompt, max_tokens=20)
    response = response.strip()
    return response.startswith("1")
```

- 推理格式转换

```python
def reasoning_output_transform(instruction, output):
    prompt = f"""从题目和解答中，提取出解答的思考过程和最终结果，思考过程用<thought>...</thought>括起来，回答过程用<answer>...</answer>括起来。最终结果用\\boxed{{}}括起来。
        注意: 是提取出给你的解答的思考过程和最终结果。不要自己解题！不要自己解题！
        1. 思考和回答都要使用和原始输入相同的语种，如果题目用中文，回答也要用中文，如果题目用英文，回答也要用英文
        2. 回答过程是思考过程的整理，不能是思考过程的简单复述
        3. 对于编写代码的题目，忠实提取代码内容，不要取代代码直接计算
        4. 如果题目是选择题，最终答案应该给出完整的选项和内容，不能只给出内容
        5. 不要脱离原来的解答自由发挥
        6. 你的输出始终以<thought>开头，以</answer>结尾
        ------
        示例输入1: 
        题目: The distance between two stars is 6.52 x 10^5 light years. What is the distance between the two stars in parsecs? (1 parsec = 3.26 light years)\nAnswer Choices: (A) 2 x 10^5 (B) 4 x 10^6 (C) 5 x 10^7 (D) 7 x 10^7 (E) 9 x 10^8
        解答: Let's think about the multi-choice question. 6.52 x 10^5 ly / (3.26 ly/parsec) = 2 x 10^5 persec\\nThe answer is A.
        示例输出1: <thought>Let's think about the multi-choice question. 6.52 x 10^5 ly / (3.26 ly/parsec) = 2 x 10^5 persec</thought><answer>The answer is \\boxed{{A}}</answer>
        ------
        示例输入2: 
        题目: 等差数列的首项是3，公差是2，求前100项的和。
        解答: 本题可先根据等差数列的性质表示出$a_n$，再根据求和公式$S_n=\\frac{{n}}{{2}}(a_1+a_n)$求出前100项和$S_{{100}}$。\\n- $a_n=1+2n$，$S_n=\\frac{{n}}{{2}}(a_1+a_n)=\\frac{{n}}{{2}}(3+1+2n)=n^2+2n$\\n- $S_{100}=100^2+2*100=10200$。
        示例输出2: <thought>本题可先根据等差数列的性质表示出$a_n$，再根据求和公式$S_n=\\frac{{n}}{{2}}(a_1+a_n)$求出前100项和$S_{{100}}$。\\n- $a_n=1+2n$，$S_n=\\frac{{n}}{{2}}(a_1+a_n)=\\frac{{n}}{{2}}(3+1+2n)=n^2+2n$\\n- $S_{100}=100^2+2*100=10200$</thought><answer>结果\\boxed{{10200}}</answer>\n
        题目: {instruction}
        解答: {output}"""

    response = vllm_chat(prompt, max_tokens=len(output) * 2)
    return response
```

- 格式验证

```python
def reasoning_output_format_validate(content):
    if content.startswith("<thought>") and content.endswith("</answer>") \
        and content.count("<thought>") == 1 and content.count("</thought>") == 1 \
        and content.count("<answer>") == 1 and content.count("</answer>") == 1 \
        and content.count("\\boxed{") == 1:
        return True
    else:
        return False
```

- 内容一致性验证

```python
def reasoning_output_content_validate(instruction, content1, content2):
    prompt = f"""比较下面对于同一个问题的两个回答，判断它们语义是否一致。
        如果回答的中间过程出现语义不一致，返回0；
        如果最终结果不完全一致（包括格式和语义，例如对于选择题，一个回答给出选项代码，一个回答给出选项内容，应该认为是不一致的），则返回0；
        
        问题: {instruction}
        ---
        回答1: {content1}
        ---
        回答2: {content2}
        ---
        注意: 直接返回1或0，不要添加任何其他内容。"""
    
    response = vllm_chat(prompt, max_tokens=20)
    response = response.strip()
    return response.startswith("1")
```

remark: 更多精细校验：
- math-verifier
- Alibaba + deepseek: https://arxiv.org/pdf/2406.14024v1

## 2. SFT对比

这一部分首先要分析我认为数学推理能力包括什么表象，如何设计一些问题来体现这些表象，然后如何对比不同模型+不同数据集训练后的表象来说明问题。

### 2.1 5个case

- case1: 最简单的 

**PROMPT**: 1+1=？

  查看是否有过度的think

- case2: 等差数列求和问题

**PROMPT**: 已知等差数列$\{a_n\}$的公差为$d=\frac{1}{2}$，且$a_2+a_4+a_6+...+a_{100}=80$，求该数列的前100项之和

  查看是否有用简便算法，这里1/2不能换成1，换成1对于小尺寸模型来说，暴力计算也很简单，但是1/2的话暴力计基本都会算错，或者算着算着陷入不断的检查、校验。所以1/2这个数值能更好地体现模型的数学计算能力和简便计算能力。

- case3: 不等式最小值问题

**PROMPT**: 若$a>0,b>0$且$a+b=2$，则$\frac{1}{a}+\frac{1}{b}$的最小值为多少？

  查看模型是否学会基本的求导，是否会用不同方式来相互映证。

- case4: 物理问题（光速叠加）

**PROMPT**: 我打开手电筒，沿着光照射的方向向前跑，光照出的速度不就是光速叠加上我移动的速度，从而超过了光速吗？

  查看模型是否理解基本的物理原理，能否进行正确的、通俗的解释。

- case5: 函数极值问题

**PROMPT**: 求函数$f(x)=(1+2x) \ln (1+x)-x$的极值

  查看模型是否能正确求导（涉及到符号计算），能否正确找出极值点并进行验证（因为这里涉及超越方程，无法直接解出临界点，人通常会先猜一个最基础的，然后验证），模型有可能学不会先猜后验证，而是用数值方法不断逼近，陷进去了。就是说，模型能否理解人类的解题思路，而非单纯的数值计算。

### 2.2 模型对比表格

<table>
  <thead>
    <tr>
      <th>case</th>
      <th><strong>DeepSeek-R1-Distill-Qwen-1.5B</strong></th>
      <th>Qwen3-0.6B</th>
      <th>Qwen3-1.7B</th>
      <th>Qwen2.5-0.5B-instruct</th>
      <th>Qwen2.5-1.5B-instruct</th>
      <th>Qwen2.5-1.5B-instruct + SFT<br/>（数据无充分治理）</th>
      <th>Qwen2.5-1.5B-instruct + SFT<br/>（数据经过充分治理）</th>
      <th>Qwen2.5-7B-instruct + SFT<br/>（数据经过充分治理）</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>comments</td>
      <td>总体正确，略有瑕疵，说明1.5B尺寸在这些问题上能够做得好</td>
      <td>过程罗嗦，正确的也是暴力求解的</td>
      <td></td>
      <td></td>
      <td></td>
      <td>虽然有时候结果对，但是通常不知所云、罗嗦</td>
      <td>经常自我重复，是否过拟合？还是训练崩了？</td>
      <td>完全正确，对比Qwen3-8B，14B，32B都是能打的</td>
    </tr>
  </tbody>
</table>

### 2.3 总结

1. 即使到了Qwen3的8B、14B、32B，复杂数学问题也主要是"硬算"出来的
2. 经过充分数据治理的SFT模型在数学推理上表现显著提升
3. 模型大小对解题能力有影响，但数据质量同样重要，下一步是提高1.5B的模型质量


## 附录

### 数据集详细分析

#### 1. DeepSeek-R1-Distill-data-110k ⭐⭐⭐⭐⭐

**基本信息**: 
- 数据量: 11万条
- 采用状态: ✅ 推荐使用

**优点**: 
1. 保留了数据来源，可追溯性强
2. 介绍了打分方式: 
   - 使用Math-verify解析问题
   - 表达式消歧处理
   - 多线程安全机制
   - 使用模型进行评分

**Case Study**: 
- 难题解答正确率高
- 甚至能够纠正题目中的错误

---

#### 2. INTELLECT-MATH-SFT-Data ⭐⭐⭐⭐

**基本信息**: 
- 数据量: 过滤后约70万条可用
- 采用状态: ✅ 推荐使用
- 评价: 量大管饱

**特点**: 
- 无遵循推理输出格式（需要转换）
- 质量较高、难度中等
- System prompt更加完善

**System Prompt示例**: 
```json
{
  "content": "Solve the following math problem efficiently and clearly. Think carefully and step by step about your response and reason before providing a final response. Conclude your response with: \n\nTherefore, the final answer is: $\\boxed{answer}$. I hope it is correct.\n\nWhere [answer] is just the final number or expression that solves the problem. If the question is a multiple choice question, [answer] should be the letter indicating your correct response (e.g. \\text{A} or \\text{B}).",
  "role": "system"
}
```

**数据验证逻辑**: 
```python
instruction = item["messages"][1]["content"]
output = item["messages"][2]["content"]
final_result = output.rsplit("\\boxed{", 1)[-1].rsplit("}", 1)[0]
if len(final_result) > 5 * len(item["ground_truth"]):  # 一些数据在犹豫二选一
    continue
final_result = "".join(final_result.replace("\\dfrac", "\\frac").split())
gt = "".join(item["ground_truth"].replace("\\dfrac", "\\frac").split())

sig1 = 1
if final_result != gt and gt not in final_result and final_result not in gt:
    sig1 = 0
sig2 = 0
try:
    if verify(parse(f"${final_result}$"), parse(f"${gt}$")):
        sig2 = 1
except:
    pass
if sig1 == 0 and sig2 == 0:
    continue
```

**Ground Truth说明**: 
- GT来源未明确说明，怀疑是从回答中抽取的
- 可用来检查回答是否异常，从而进行过滤

---

#### 3. NuminaMath-QwQ-CoT ⭐⭐⭐

**基本信息**: 
- 数据量: 500万条
- 采用状态: ⚠️ 谨慎使用
- 评价: 量大但质量存在问题

**问题分析**: 
- 无遵循推理输出格式
- 训练效果不理想: 
  - 500万条训练7B模型（intellect-math应该也是基于qwen训练的）
  - 只达到deepseek-R1-distill-Qwen1.5B的水平
  - 对比AIME2024、MATH-500数据，效果不如Qwen3 1.7B
  - 距离deepseek-R1-distill-Qwen7B相差较大
  - 说明数据质量存在一定问题

**Case Study发现的问题**: 

| 问题类型 | Problem ID | 具体描述 | 严重程度 |
|----------|-----------|----------|----------|
| 数据泄露 | 650008 | 答案结束后出现"human assistant"字样 | 🔴 高 |
| 超长截断 | 650002 | 证明题超长被截断（题目太难） | 🟡 中 |
| 正确证明 | 650560 | 证明看起来是对的 | 🟢 无问题 |
| 缺少条件 | 650576 | 疑似缺少图片，提到"The figure" | 🔴 高 |
| 难度大 | - | 部分题目难以理解 | 🟡 中 |
| 假错误(GT错) | - | GT错误，解答中的96是正确的 | 🟡 中 |
| 假错误(都对) | 650569 | GT和解答都正确但被标记为错 | 🟡 中 |
| 真错误 | - | 确实存在错误 | 🔴 高 |

**证明题情况**: 
- 较多证明题（prompt含有"Prove that"字样）
- 部分证明正确，部分被截断

---

#### 4. qwq_synthetic_sft_data_math ⭐ （不采用）

**问题**: 
- ❌ 没有readme
- ❌ 质量非常差
- ❌ 几乎所有的问题和答案都是错配的

**结论**: 不建议使用

---

#### 5. MathInstruct ⭐⭐⭐⭐

**基本信息**: 
- 参考论文: https://arxiv.org/pdf/2309.05653v3
- 采用状态: ✅ 推荐使用

**重要启发**: 
- Paper的附录中有例子证明: **PoT（Program of Thought）对比CoT是很好的补充**
- 受此启发，数学解题能力建设中也需要编程的tool调用

**特点**: 
- ✅ 质量较高，答案和过程一般都没有问题
- ⚠️ 不是推理格式，需要转换和校验

**Case Study**: 
- 存在部分格式不对的情况

---

#### 6. sft-data-math ⭐⭐

**基本问题**: 
- ❌ 无readme
- ⚠️ 题目和答案存在多处瑕疵

**Case Study发现的问题**: 

| 问题类型 | 具体描述 | 备注 | 严重程度 |
|----------|----------|------|----------|
| 选项缺失 | 题目选项中没有正确答案（-1+5i），解答也不对 | - | 🔴 高 |
| 题目不严谨 | 题目没有唯一解 | remark: 50x=60(x-y) x,y是整数 | 🟡 中 |
| 答案瑕疵 | 区间的开闭和规范写法问题 | 正确答案应为$(1/4,1/2]$ | 🟡 中 |

---

#### 7. OpenO1-SFT-MATH ⭐⭐

**基本信息**: 
- 采用状态: ⚠️ 需要大量处理后使用

**存在的问题**: 

| 问题类型 | 具体描述 | 处理方法 |
|----------|----------|----------|
| 训练效果差 | Readme显示训练后分数下降 | - |
| 数据重复 | Query重复 | 需要去重 |
| 不遵循指令 | 含有"write a program in Python"的题目，最终却是直接数学计算求解 | 全部删除 |
| 格式错误 | `<Thought>`,`</Thought>`,`<Output>`,`</Output>`数量不严格等于1 | 删除不符合的数据 |
| 数据错误 | 存在错误 | 参考: https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT/discussions/15 |

**处理建议**: 
1. 对Query进行去重
2. 删除不遵循指令的数据
3. 删除格式不符合的数据
4. 进行正确性过滤

---

#### 8. Alpaca系列

**共同特点**: 
- 都是类型题
- **启发**: 对于固定算法的计算，需要编程工具

##### alpaca-sft-math-tasks ⭐⭐⭐（采样0.01，部分采用）

**包含的题型**: 
- 求解GCD（辗转相除法）
- 证明素数
- 任何一对素数中找出和为N的最小素数（哥德巴赫猜想）

##### alpaca-sft-math-factorial （不采用）

**题型**: n! % M 计算题

##### alpaca-sft-math-hard2 （审批中）

**状态**: 待审批

---

#### 9. 简单数据集

##### tulu-3-sft-math ⭐⭐⭐

**基本信息**: 
- 采用状态: ✅ 用于训练无think模式

**特点**: 
- 偏简单
- 基本正确
- 无think（也确实不需要）

**用途**: 加入用于训练无think模式

---

##### Belle_school_math ⭐⭐ （不采用）

**特点**: 
- 偏简单
- 基本正确
- 无think（也确实不需要）

**问题**: 
- ❌ 都是简单的加减乘除应用题
- ❌ 题型和tulu3有重复
- ❌ 题目可能是生成的，质量不高

**结论**: 不建议使用

---

##### kyara-chinese-math ⭐⭐ （不采用）

**特点**: 
- 偏简单
- 基本正确
- 无think（也确实不需要）

**问题**: 
- ❌ 都是简单的加减乘除应用题
- ❌ 题型和tulu3有重复

**结论**: 不建议使用

---

